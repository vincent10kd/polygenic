#' @title create_prs
#'
#' @description Create a polygenic risk score based on summary statistics from prior GWAS/pQTL discovery studies.
#'
#' @param variant_data An object of format output by extract_variants().
#' @param gwas_info An object generated by get_trait_variants() or get_pQTLs().
#' @param remove_indels If TRUE, removes indels.
#' @param imp_threshold Imputation quality threshold, based on R^2. Any variant with lower imputation R^2 is removed.
#' @param binary_outcome Set to TRUE for binary traits, and FALSE for continuous outcomes (including pQTLs).
#' @param exclude_extreme_associations If TRUE, removes variants with an odds ratio > 5 or <1/5.
#' @param LDplot If TRUE, plots the LD matrix (squared correlation matrix of variants).
#' @param pruning_threshold Variants in LD >= pruning_threshold with other variants are removed, keeping higher MAF variants.
#' @param pval_threshold Variants with GWAS p-values > pval_threshold are discarded. Set to 1 to turn off.
#' @param scale Centers and standardizes the polygenic risk score if TRUE.
#' @param flowchart If TRUE, plots a flowchart describing the creation of the polygenic risk score.
#'
#' @return A list containing several data.frames with all relevant information. The risk score is stored in element 'prs'.
#' @examples
#' # vte_prs <- create_prs(vte_extracted_variants, vte_gwas_info)
#' # hist(vte_prs$prs$prs)
#' @export

create_prs <- function(variant_data, # expects an object of format output by extract_variants()
                       gwas_info, # expects an object of format output by get_trait_variants()
                       remove_indels=FALSE,
                       imp_threshold=.8,
                       binary_outcome=TRUE,
                       exclude_extreme_associations=TRUE,
                       LDplot=FALSE, # is overridden by flowchart if it is TRUE
                       pruning_threshold=.75,
                       pval_threshold=5e-8, # can be 'turned off' by setting to 1
                       scale=FALSE, # center and standardize the score
                       flowchart=TRUE){
  start_time <- Sys.time()
  require(metafor)
  # create empty result and exclusions list ----
  res_list <- list()
  e <- list()
  # preprocess: remove indels, multiallelic SNPs
  if(remove_indels==TRUE){
    ndif <- nchar(variant_data$fix$REF)-nchar(variant_data$fix$ALT)
    if(any(ndif>0)){
      rind <- which(ndif>0)
      variant_data$fix <- variant_data$fix[-rind,]
      variants_left <- variant_data$fix$ID
      variant_data$gt <- variant_data$gt[,which(colnames(variant_data$gt)%in%variants_left)]
    }
  }
  dups <- which(duplicated(data.frame(variant_data$fix)$ID))
  if(length(dups)>0){
    variant_data$fix <- variant_data$fix[-c(dups,dups-1),]
    variant_data$gt <- variant_data$gt[-c(dups,dups-1),]
    cat('> Removed',length(dups),'duplicate variants (e.g. triallelic SNPs).\n')
  }
  v <- variant_data$fix
  unique_variants <- unique(v$ID)
  no_of_variants <- length(unique_variants)
  cat('> A total of',no_of_variants,'variants was retrieved.\n')
  e$variants_retrieved <- no_of_variants
  # check whether all variants were dropped
  drop_check <- function(v){
    if(nrow(v)==0) stop('All variants have been dropped. Try different tuning parameters.')
  }
  # take subset with imputation_quality>= imp_threshold; remove unnecessary columns ----
  v$imp_qual <- v$DR2
  low_imp_qual_l <- length(unique(v$ID[v$imp_qual<imp_threshold]))
  v <- subset(v, imp_qual >= imp_threshold)
  cat('> Dropped',low_imp_qual_l,'variants with imputation R^2 below threshold.\n')
  e$low_imp_qual <- low_imp_qual_l
  v <- v[,-c(6:10)]
  unique_variants <- unique(v$ID)
  drop_check(v)
  # take out SNPs with no variance in dataset (i.e. constants)
  varv <- suppressWarnings(sapply(variant_data$gt,sd))
  novar <- names(which(is.na(varv)|varv==0))
  variant_data$gt <- variant_data$gt[,!colnames(variant_data$gt) %in% novar]
  v <- subset(v, !ID %in% novar)
  g <- gwas_info
  g <- subset(g, !variant_id %in% novar)
  l0 <- length(unique_variants) - length(unique(v$ID))
  unique_variants <- unique(v$ID)
  cat('> Dropped',l0,'variants with zero variance in the data.\n')
  e$no_variance <- l0
  drop_check(v)
  # load in gwas info for the associated trait (output from get_snps()) ----
  g <- subset(g, variant_id %in% unique_variants)
  l1 <- length(unique(v$ID[v$ID %in% unique(g$variant_id)]))
  cat('> Dropped',length(unique_variants)-l1,'variants that did not match with gwas_info.\n')
  e$missing_from_gwasinfo <- length(unique_variants)-l1
  g
  if(binary_outcome==TRUE){
    g <- subset(g, !is.na(or_per_copy_number))
  }
  else{g <- subset(g, !is.na(beta_coefficient))}
  g <- g[!duplicated(g),]
  l2 <- length(unique(v$ID[v$ID %in% unique(g$variant_id)]))
  cat('> Dropped',l1-l2,'variants with missing effect sizes.\n')
  e$missing_effectsize <- l1-l2
  if(binary_outcome==TRUE){g$effect_size <- log(g$or_per_copy_number)}
  else{g$effect_size <- g$beta_coefficient}
  g <- subset(g, !is.na(risk_allele))
  l3 <- length(unique(v$ID[v$ID %in% unique(g$variant_id)]))
  cat('> Dropped',l2-l3,'variants with missing risk alleles.\n')
  e$missing_risk_allele <- l2-l3
  drop_check(v)
  # if multiple logORs reported, get meta-analytic estimate ----
  snp_ind <- aggregate(effect_size~variant_id,g,function(x) length(unique(x)))
  multiOR_l <- sum(as.numeric(snp_ind[,2]>1))
  id_list <- list()
  for(i in 1:length(unique(snp_ind$variant_id))){
    meta <- g[g$variant_id==unique(snp_ind$variant_id)[i],]
    if(nrow(meta)>1){
      if(0%in%meta$pvalue){meta$pvalue[which(meta$pvalue==0)] <- min(meta$pvalue[meta$pvalue>0])}
      meta$standard_error <- ifelse(is.na(meta$standard_error),
                                    abs(meta$effect_size/qnorm(meta$pvalue/2)),
                                    meta$standard_error)
      meta_est <- suppressWarnings(metafor::rma(yi=meta$effect_size,
                                                sei=meta$standard_error))
    }
    id_list[[i]] <- g[g$variant_id == unique(snp_ind$variant_id)[i],][1,]
    if(nrow(meta)>1){
      id_list[[i]]$effect_size <- meta_est$beta
      id_list[[i]]$standard_error <- meta_est$se
    }
  }
  g <- do.call('rbind', id_list)
  cat('> In case of multiple effect sizes (there were',multiOR_l,
      'occurrences), used meta-analytic estimate for pooled effect size.\n')
  e$multiple_effectsizes <- multiOR_l
  # add to result list ----
  v <- subset(v, ID %in% unique(g$variant_id))
  g <- subset(g, variant_id %in% unique(v$ID))
  unique_variants <- unique(v$ID)
  # compare risk allele gwas catalog and vcf file 'ALT' allele ----
  radf <- list()
  for(i in 1:length(unique_variants)){
    RA_g <- g$risk_allele[g$variant_id==unique_variants[i]]
    RA_v <- v$ALT[v$ID==unique_variants[i]]
    radf[[i]] <- c(RA_g, RA_v)
  }
  radf <- data.frame(do.call('rbind',radf))
  colnames(radf) <- c('risk_allele_gwas','risk_allele_vcf')
  rownames(radf) <- unique_variants

  radf$ref_allele_vcf <- v$REF[v$ID %in% rownames(radf)]
  radf$complement_base_gwas <- rep(NA,nrow(radf))
  radf$complement_base_vcf <- rep(NA,nrow(radf))
  radf$complement_base_vcf_ref <- rep(NA,nrow(radf))
  # get complement base ----
  strandflip <- function(e) switch(e, 'A'='T','T'='A','C'='G','G'='C')
  for(i in 1:nrow(radf)){
    s1 <- strandflip(radf$risk_allele_gwas[i])
    s2 <- strandflip(radf$risk_allele_vcf[i])
    s3 <- strandflip(radf$ref_allele_vcf[i])
    radf$complement_base_gwas[i] <- ifelse(is.null(s1),NA,s1)
    radf$complement_base_vcf[i] <- ifelse(is.null(s2),NA,s2)
    radf$complement_base_vcf_ref[i] <- ifelse(is.null(s3),NA,s3)
  }
  # comparison ----
  radf$different <- radf$risk_allele_gwas!=radf$risk_allele_vcf&
    radf$complement_base_gwas!=radf$risk_allele_vcf
  radf$same_as_ref <- radf$risk_allele_gwas==radf$ref_allele_vcf|
    radf$risk_allele_gwas==radf$complement_base_vcf_ref
  radf$reverse_sign <- ifelse(radf$different==FALSE, 0, 1)
  reverse_sign_SNPs <- rownames(radf)[which(radf$reverse_sign==1)]
  cat('>',length(reverse_sign_SNPs),'variants had opposite risk allele coding with the GWAS catalog.\n')
  e$opposite_allele_coding <- length(reverse_sign_SNPs)
  # reverse logORs ----
  g$effect_size_final <- g$effect_size
  reverse_ind <- which(g$variant_id%in%reverse_sign_SNPs)
  g$effect_size_final[reverse_ind] <- -1*g$effect_size_final[reverse_ind]
  cat('>',length(reverse_ind),'effect sizes had their sign inverted. The new effect sizes are stored as effect_size_final.\n')
  e$inverted_sign <- length(reverse_ind)
  # exclude variants with extreme ORs (~ OR of 5 or 1/5) ----
  if(exclude_extreme_associations==TRUE){
    if(binary_outcome==TRUE){
      extreme_variants <- unique(g$variant_id[which(abs(log(g$or_per_copy_number))>1.6)])
      g <- subset(g, !variant_id %in% extreme_variants)
      v <- subset(v, !ID %in% extreme_variants)
      if(length(extreme_variants)>0){
        cat('> Dropped',length(extreme_variants),'variants with extreme ORs (>5 or <1/5).\n')
      }
      e$extreme_effectsize_variants_dropped <- length(extreme_variants)
      unique_variants <- v$ID
      drop_check(v)
    }
    else{
      cat('> No variants dropped (exclude_extreme_associations only compatible with binary outcomes).\n')
      e$extreme_effectsize_variants_dropped <- 0
    }
  }
  # now read in the actual allele data ----
  d <- variant_data$gt
  d <- d[, which(colnames(d) %in% unique_variants)]
  # Linkage disequillibrium in data ----
  LD_dat <- cor(d)
  LD <- LD_dat
  if(LDplot==TRUE){
    heatmap(LD)
  }
  # Prune high LD variants, leave only the one with higher MAF in the data ----
  LD2 <- round(LD^2,2)
  LDlotri <- lower.tri(LD2)*1
  LDlotri[LDlotri==0] <- NA
  LD2 <- LD2*LDlotri
  # pairs
  LDtab <- which(LD2>=pruning_threshold, arr.ind=TRUE)
  if(nrow(LDtab)>0){
    LDtab2 <- data.frame(matrix(NA,nrow=nrow(LDtab), ncol=2))
    for(i in 1:nrow(LDtab)){
      LDtab2[i,1] <- rownames(LD2)[LDtab[i,1]]
      LDtab2[i,2] <- colnames(LD2)[LDtab[i,2]]
    }
    colnames(LDtab2) <- c('rowSNP','colSNP')
    # distinguish repeating SNP names, reshape to wide format
    LDtab2$rep <- c(0,(diff(as.numeric(factor(LDtab2$rowSNP)))==0)*1)
    LDtab2 <- suppressWarnings(reshape(LDtab2, idvar='rowSNP', timevar='rep', direction='wide'))
    # compare minor allele frequencies ----
    keep_SNPs <- rep(NA, nrow(LDtab2))
    for(i in 1:nrow(LDtab2)){
      vn <- as.character(na.omit(as.character(LDtab2[i,grep('SNP',colnames(LDtab2))])))
      maf <- sapply(d[vn],sum)
      freq <- which(maf==max(maf))[1]
      keep_SNPs[i] <- LDtab2[i,freq]
    }
    remove_SNPs <- setdiff(na.omit(unique(unlist(LDtab2))),keep_SNPs)
    # subset
    d <- d[, -which(colnames(d) %in% remove_SNPs)]
    g <- subset(g, !variant_id %in% remove_SNPs)
    v <- subset(v, !ID %in% remove_SNPs)
    cat('> Dropped ',length(remove_SNPs),' variants in high LD (R^2>=',pruning_threshold,
        ') with other variants.\n',sep='')
    e$high_LD_snps_pruned <- length(remove_SNPs)
    drop_check(v)
  }
  if(nrow(LDtab)==0){e$high_LD_snps_pruned <- 0}
  # p-value thresholding
  prem_SNPs <- unique(g$variant_id[which(g$pvalue>pval_threshold)])
  if(length(prem_SNPs)>0){
    g <- subset(g, pvalue<=pval_threshold)
    d <- d[, -which(colnames(d) %in% prem_SNPs)]
    v <- subset(v, !ID %in% prem_SNPs)
  }
  cat('> Removed ',length(prem_SNPs),' variants by p-value thresholding (threshold=',
      pval_threshold,')\n',sep='')
  e$SNPs_removed_by_pval_thresholding <- length(prem_SNPs)
  remaining_l <- length(unique(v$ID))
  cat('>',remaining_l,'variants remaining.\n')
  e$remaining_snps <- remaining_l
  drop_check(v)
  # create the weighted polygenic risk score ----
  g <- g[match(colnames(d),g$variant_id),]
  effectsize <- as.matrix(g$effect_size_final)
  prs <- as.matrix(d) %*% effectsize
  cat('> Weighted polygenic score created using',length(effectsize),'SNPs.\n')
  # center and standardize
  if(scale==TRUE){
    prs <- scale(prs)
    cat('> Centered and standardized the score.\n')
  }
  # add information about reference genome to process_log
  e <- do.call('c',e)
  # fill result list ----
  res_list$process_log <- e
  res_list$gwas_info <- g
  res_list$variant_info <- v
  res_list$allele_data <- d
  res_list$risk_allele_df <- radf
  res_list$sample_ids <- as.matrix(rownames(d))
  res_list$prs <- data.frame(id=res_list$sample_ids,prs=prs)
  rownames(res_list$prs) <- NULL
  res_list$ld_matrix <- LD_dat
  if(nrow(LDtab)>0){res_list$ld_pairs <- LDtab2}
  cat('> Returned a list of results with the following dimensions:\n')
  print(lapply(res_list, dim))
  end_time <- Sys.time()
  cat('> Creation of the PRS took',difftime(end_time,start_time,units='secs'),'seconds.\n')
  if(flowchart==TRUE){
    library(PRISMAstatement)
    print(flow_exclusions(incl_counts=c(e[1],
                                        e[1]-e[2],
                                        e[1]-e[2]-e[3],
                                        e[1]-e[2]-e[3]-e[4],
                                        e[1]-e[2]-e[3]-e[4]-sum(e[5:6]),
                                        e[1]-e[2]-e[3]-e[4]-sum(e[5:6])-e[10],
                                        e[1]-e[2]-e[3]-e[4]-sum(e[5:6])-e[10]-e[11],
                                        e[1]-e[2]-e[3]-e[4]-sum(e[5:6])-e[10]-e[11]-e[12]),
                          total_label='Total variants retrieved',
                          incl_labels=c('High imputation quality variants',
                                        'Variants with non-zero variance',
                                        'Variants reported in GWAS catalog',
                                        'Variants with complete information',
                                        'Variants with non-extreme effect sizes',
                                        'Variants sufficiently independent',
                                        'Variants used in the weighted score'),
                          excl_labels=c(paste0('Low imputation quality (R^2<',imp_threshold,')'),
                                        'Variants with zero variance in the data',
                                        'Variants not found in GWAS catalog information',
                                        'Missing effect size or risk allele',
                                        'Variants with extreme effect sizes (99th percentile)',
                                        'Variants in high LD with other included variants with higher MAF',
                                        paste0('Variants with p-value above threshold (',pval_threshold,')'))))
  }
  invisible(return(res_list))
}
